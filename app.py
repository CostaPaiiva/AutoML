import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import time
import base64
import joblib
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ========== CONFIGURA√á√ÉO ==========
st.set_page_config(
    page_title="AutoML Completo",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ========== CSS PERSONALIZADO ==========
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1E88E5;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-card {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin: 10px 0;
    }
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        color: #155724;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .stButton > button {
        width: 100%;
        font-weight: bold;
    }
</style>
""", unsafe_allow_html=True)

# ========== PROCESSAMENTO DE DADOS SIMPLES ==========
class SimpleDataProcessor:
    def __init__(self, target_column=None):
        self.target_column = target_column
    
    def process(self, data):
        """Processamento simples e √† prova de erros"""
        try:
            # Se n√£o tiver target, usar √∫ltima coluna
            if self.target_column is None:
                self.target_column = data.columns[-1]
            
            # Verificar se target existe
            if self.target_column not in data.columns:
                st.error(f"Coluna '{self.target_column}' n√£o encontrada no dataset.")
                # Usar √∫ltima coluna como fallback
                self.target_column = data.columns[-1]
            
            # Separar X e y
            X = data.drop(columns=[self.target_column]).copy()
            y = data[self.target_column].copy()
            
            # Detectar tipo de problema
            if y.dtype == 'object' or len(y.unique()) <= 10:
                problem_type = 'classification'
            else:
                problem_type = 'regression'
            
            st.info(f"‚úÖ Tipo de problema detectado: **{problem_type.upper()}**")
            
            # 1. Limpeza b√°sica
            X_clean = self.clean_data(X)
            
            # 2. Codificar categ√≥ricas
            X_encoded = self.encode_categorical(X_clean)
            
            # 3. Lidar com missing values
            X_final = self.handle_missing(X_encoded)
            
            # 4. Escalar features (opcional, apenas se solicitado)
            if st.session_state.get('scale_features', True):
                X_final = self.scale_features(X_final)
            
            return X_final, y, problem_type
            
        except Exception as e:
            st.error(f"‚ùå Erro no processamento: {str(e)}")
            # Fallback: processamento m√≠nimo
            return self.minimal_process(data)
    
    def clean_data(self, X):
        """Limpeza b√°sica dos dados"""
        # Remover colunas com muitos missing (>50%)
        missing_threshold = 0.5
        missing_pct = X.isnull().mean()
        cols_to_drop = missing_pct[missing_pct > missing_threshold].index.tolist()
        
        if cols_to_drop:
            X = X.drop(columns=cols_to_drop)
            st.info(f"üìâ Removidas {len(cols_to_drop)} colunas com muitos valores faltantes")
        
        # Remover colunas constantes
        constant_cols = [col for col in X.columns if X[col].nunique() == 1]
        if constant_cols:
            X = X.drop(columns=constant_cols)
            st.info(f"‚ö° Removidas {len(constant_cols)} colunas constantes")
        
        return X
    
    def encode_categorical(self, X):
        """Codifica√ß√£o de vari√°veis categ√≥ricas"""
        categorical_cols = X.select_dtypes(include=['object']).columns
        
        for col in categorical_cols:
            # Se tiver poucas categorias, usar one-hot
            if X[col].nunique() <= 10:
                # One-hot encoding
                dummies = pd.get_dummies(X[col], prefix=col, drop_first=True)
                X = pd.concat([X.drop(columns=[col]), dummies], axis=1)
            else:
                # Label encoding para muitas categorias
                X[col] = pd.factorize(X[col])[0]
        
        return X
    
    def handle_missing(self, X):
        """Tratamento de valores faltantes"""
        # Para colunas num√©ricas
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        if len(numeric_cols) > 0:
            # Usar mediana (mais robusta que m√©dia)
            X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].median())
        
        # Para colunas n√£o num√©ricas (ap√≥s encoding)
        other_cols = X.select_dtypes(exclude=[np.number]).columns
        for col in other_cols:
            X[col] = X[col].fillna(0)
        
        return X
    
    def scale_features(self, X):
        """Escalonamento simples de features"""
        from sklearn.preprocessing import StandardScaler
        
        numeric_cols = X.select_dtypes(include=[np.number]).columns
        
        if len(numeric_cols) > 0:
            # Apenas scale colunas com desvio padr√£o > 0
            cols_to_scale = [col for col in numeric_cols if X[col].std() > 0]
            
            if cols_to_scale:
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X[cols_to_scale])
                X[cols_to_scale] = X_scaled
                st.info(f"üìä {len(cols_to_scale)} features escaladas")
        
        return X
    
    def minimal_process(self, data):
        """Processamento m√≠nimo de fallback"""
        # Target √© a √∫ltima coluna
        target_col = data.columns[-1]
        X = data.iloc[:, :-1]
        y = data.iloc[:, -1]
        
        # Detectar tipo
        if y.dtype == 'object' or len(y.unique()) <= 10:
            problem_type = 'classification'
        else:
            problem_type = 'regression'
        
        # Apenas fillna
        X = X.fillna(0)
        
        return X, y, problem_type

# ========== TREINAMENTO DE MODELOS ==========
class SimpleModelTrainer:
    def __init__(self, problem_type):
        self.problem_type = problem_type
        self.models = {}
        self.results = {}
        self.best_model = None
        self.best_model_name = ""
    
    def train_models(self, X, y):
        """Treina v√°rios modelos de ML"""
        from sklearn.model_selection import train_test_split, cross_val_score
        from sklearn.metrics import accuracy_score, f1_score, r2_score, mean_squared_error
        
        st.info("ü§ñ Iniciando treinamento de modelos...")
        
        # Split dos dados
        if self.problem_type == 'classification':
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42, stratify=y
            )
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=0.2, random_state=42
            )
        
        # Obter modelos
        models = self.get_models()
        
        # Barra de progresso
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        results_list = []
        
        for i, (name, model) in enumerate(models.items()):
            try:
                status_text.text(f"üìä Treinando {name}...")
                
                # Valida√ß√£o cruzada simples
                cv_scores = cross_val_score(
                    model, X_train, y_train, 
                    cv=3, 
                    scoring='accuracy' if self.problem_type == 'classification' else 'r2',
                    n_jobs=-1
                )
                
                # Treinar modelo
                model.fit(X_train, y_train)
                
                # Previs√µes
                y_pred = model.predict(X_test)
                
                # M√©tricas
                if self.problem_type == 'classification':
                    metrics = {
                        'accuracy': accuracy_score(y_test, y_pred),
                        'f1_score': f1_score(y_test, y_pred, average='weighted'),
                        'cv_mean': cv_scores.mean(),
                        'cv_std': cv_scores.std()
                    }
                else:
                    metrics = {
                        'r2': r2_score(y_test, y_pred),
                        'rmse': np.sqrt(mean_squared_error(y_test, y_pred)),
                        'cv_mean': cv_scores.mean(),
                        'cv_std': cv_scores.std()
                    }
                
                # Salvar
                self.models[name] = model
                self.results[name] = metrics
                results_list.append((name, metrics))
                
                # Atualizar progresso
                progress_bar.progress((i + 1) / len(models))
                
            except Exception as e:
                st.warning(f"‚ö†Ô∏è {name}: {str(e)}")
                continue
        
        # Determinar melhor modelo
        if self.results:
            self.determine_best_model()
            st.success(f"‚úÖ Treinamento completo! {len(self.results)} modelos treinados")
            st.success(f"üèÜ Melhor modelo: **{self.best_model_name}**")
        else:
            st.error("‚ùå Nenhum modelo foi treinado com sucesso!")
        
        return self.results, self.best_model_name
    
    def get_models(self):
        """Retorna lista de modelos para treinar"""
        if self.problem_type == 'classification':
            from sklearn.linear_model import LogisticRegression
            from sklearn.ensemble import (
                RandomForestClassifier, GradientBoostingClassifier,
                AdaBoostClassifier
            )
            from sklearn.svm import SVC
            from sklearn.neighbors import KNeighborsClassifier
            from sklearn.tree import DecisionTreeClassifier
            from sklearn.naive_bayes import GaussianNB
            
            models = {
                'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),
                'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
                'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),
                'K-Neighbors': KNeighborsClassifier(n_jobs=-1),
                'Decision Tree': DecisionTreeClassifier(random_state=42),
                'AdaBoost': AdaBoostClassifier(random_state=42),
                'Naive Bayes': GaussianNB()
            }
        else:
            from sklearn.linear_model import LinearRegression, Ridge, Lasso
            from sklearn.ensemble import (
                RandomForestRegressor, GradientBoostingRegressor,
                AdaBoostRegressor
            )
            from sklearn.svm import SVR
            from sklearn.neighbors import KNeighborsRegressor
            from sklearn.tree import DecisionTreeRegressor
            
            models = {
                'Linear Regression': LinearRegression(n_jobs=-1),
                'Ridge Regression': Ridge(random_state=42),
                'Lasso Regression': Lasso(random_state=42),
                'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1),
                'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),
                'K-Neighbors': KNeighborsRegressor(n_jobs=-1),
                'Decision Tree': DecisionTreeRegressor(random_state=42),
                'AdaBoost': AdaBoostRegressor(random_state=42)
            }
        
        return models
    
    def determine_best_model(self):
        """Determina o melhor modelo baseado nas m√©tricas"""
        if not self.results:
            return
        
        if self.problem_type == 'classification':
            # Ordenar por accuracy
            sorted_models = sorted(self.results.items(), 
                                  key=lambda x: x[1]['accuracy'], 
                                  reverse=True)
        else:
            # Ordenar por r2
            sorted_models = sorted(self.results.items(), 
                                  key=lambda x: x[1]['r2'], 
                                  reverse=True)
        
        self.best_model_name = sorted_models[0][0]
        self.best_model = self.models[self.best_model_name]
    
    def get_ranking(self):
        """Retorna ranking dos modelos como DataFrame"""
        if not self.results:
            return pd.DataFrame()
        
        ranking_data = []
        for name, metrics in self.results.items():
            if self.problem_type == 'classification':
                ranking_data.append({
                    'Modelo': name,
                    'Acur√°cia': f"{metrics['accuracy']:.4f}",
                    'F1-Score': f"{metrics['f1_score']:.4f}",
                    'CV Score': f"{metrics['cv_mean']:.4f}"
                })
            else:
                ranking_data.append({
                    'Modelo': name,
                    'R¬≤': f"{metrics['r2']:.4f}",
                    'RMSE': f"{metrics['rmse']:.4f}",
                    'CV Score': f"{metrics['cv_mean']:.4f}"
                })
        
        df = pd.DataFrame(ranking_data)
        
        # Ordenar
        sort_col = 'Acur√°cia' if self.problem_type == 'classification' else 'R¬≤'
        df = df.sort_values(sort_col, ascending=False)
        df.insert(0, 'Posi√ß√£o', range(1, len(df) + 1))
        
        return df

# ========== APLICA√á√ÉO PRINCIPAL ==========
class AutoMLApp:
    def __init__(self):
        # Inicializar estado da sess√£o
        if 'step' not in st.session_state:
            st.session_state.step = 1
        if 'data' not in st.session_state:
            st.session_state.data = None
        if 'processed' not in st.session_state:
            st.session_state.processed = False
        if 'results' not in st.session_state:
            st.session_state.results = None
        if 'scale_features' not in st.session_state:
            st.session_state.scale_features = True
    
    def run(self):
        """Executa a aplica√ß√£o completa"""
        # Cabe√ßalho
        st.markdown('<h1 class="main-header">üöÄ AutoML Completo - Sistema Inteligente</h1>', 
                   unsafe_allow_html=True)
        
        # Barra de progresso
        self.show_progress()
        
        # Conte√∫do por passo
        if st.session_state.step == 1:
            self.step_upload()
        elif st.session_state.step == 2:
            self.step_process()
        elif st.session_state.step == 3:
            self.step_train()
        elif st.session_state.step == 4:
            self.step_results()
    
    def show_progress(self):
        """Mostra barra de progresso"""
        steps = ["üì• Upload", "üîß Processar", "ü§ñ Treinar", "üìä Resultados"]
        current = st.session_state.step - 1
        
        cols = st.columns(len(steps))
        for i, col in enumerate(cols):
            with col:
                if i < current:
                    st.success(f"‚úÖ {steps[i]}")
                elif i == current:
                    st.info(f"‚è≥ {steps[i]}")
                else:
                    st.write(f"üìå {steps[i]}")
        
        st.progress(current / (len(steps) - 1))
    
    def step_upload(self):
        """Passo 1: Upload do dataset"""
        st.markdown("## üì• Upload do Dataset")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            uploaded_file = st.file_uploader(
                "Escolha um arquivo CSV", 
                type=['csv'],
                help="Fa√ßa upload do seu dataset em formato CSV"
            )
            
            if uploaded_file:
                try:
                    # Ler o arquivo
                    st.session_state.data = pd.read_csv(uploaded_file)
                    st.success(f"‚úÖ Dataset carregado com sucesso!")
                    
                    # Mostrar informa√ß√µes
                    st.write(f"**Formato:** {st.session_state.data.shape[0]} linhas √ó {st.session_state.data.shape[1]} colunas")
                    
                    # Mostrar preview
                    with st.expander("üìã Visualizar primeiras linhas"):
                        st.dataframe(st.session_state.data.head(), use_container_width=True)
                    
                    # Informa√ß√µes do dataset
                    with st.expander("üìä Informa√ß√µes do dataset"):
                        buffer = io.StringIO()
                        st.session_state.data.info(buf=buffer)
                        st.text(buffer.getvalue())
                        
                        # Valores faltantes
                        missing = st.session_state.data.isnull().sum()
                        if missing.sum() > 0:
                            st.warning(f"‚ö†Ô∏è {missing.sum()} valores faltantes encontrados")
                    
                    # Selecionar target
                    target_col = st.selectbox(
                        "üéØ Selecione a coluna target (vari√°vel a ser prevista):",
                        options=st.session_state.data.columns.tolist(),
                        index=len(st.session_state.data.columns) - 1,
                        help="Esta √© a vari√°vel que os modelos v√£o tentar prever"
                    )
                    
                    st.session_state.target_col = target_col
                    
                    # Configura√ß√µes opcionais
                    with st.expander("‚öôÔ∏è Configura√ß√µes avan√ßadas"):
                        st.session_state.scale_features = st.checkbox(
                            "Escalar features automaticamente", 
                            value=True,
                            help="Normaliza as features para melhor performance dos modelos"
                        )
                    
                    # Bot√£o para continuar
                    if st.button("‚ñ∂Ô∏è Processar Dados", type="primary", use_container_width=True):
                        st.session_state.step = 2
                        st.rerun()
                        
                except Exception as e:
                    st.error(f"‚ùå Erro ao ler arquivo: {str(e)}")
        
        with col2:
            st.markdown("""
            ### üìã Como Funciona
            
            1. **Upload CSV**
               - Qualquer dataset em formato CSV
               - Processamento autom√°tico
            
            2. **Processamento**
               - Limpeza de dados
               - Codifica√ß√£o autom√°tica
               - Tratamento de valores faltantes
            
            3. **Treinamento**
               - 7+ algoritmos de ML
               - Valida√ß√£o cruzada
               - Sele√ß√£o do melhor modelo
            
            4. **Resultados**
               - Ranking completo
               - Dashboard interativo
               - Exporta√ß√£o de resultados
            
            ### üéØ Tipos Suportados
            
            ‚Ä¢ **Classifica√ß√£o**
              - Previs√£o de categorias
              - Ex: spam/n√£o spam
            
            ‚Ä¢ **Regress√£o**
              - Previs√£o de valores num√©ricos
              - Ex: pre√ßos, temperaturas
            """)
    
    def step_process(self):
        """Passo 2: Processamento dos dados"""
        st.markdown("## üîß Processamento de Dados")
        
        if st.session_state.data is None:
            st.warning("‚ö†Ô∏è Nenhum dataset carregado.")
            if st.button("‚¨ÖÔ∏è Voltar para Upload"):
                st.session_state.step = 1
                st.rerun()
            return
        
        # Processar dados
        with st.spinner("Processando dados..."):
            processor = SimpleDataProcessor(target_column=st.session_state.target_col)
            
            # Adicionar configura√ß√£o de scaling
            processor.scale_features_enabled = st.session_state.scale_features
            
            X, y, problem_type = processor.process(st.session_state.data)
            
            # Salvar no estado
            st.session_state.X = X
            st.session_state.y = y
            st.session_state.problem_type = problem_type
            st.session_state.processed = True
        
        # Mostrar resultados do processamento
        st.success("‚úÖ Processamento conclu√≠do!")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Tipo de Problema", problem_type.upper())
        
        with col2:
            st.metric("Features", X.shape[1])
        
        with col3:
            st.metric("Amostras", X.shape[0])
        
        # Mostrar informa√ß√µes dos dados processados
        with st.expander("üìä Dados Processados"):
            tab1, tab2 = st.tabs(["üìã Amostra", "üìà Estat√≠sticas"])
            
            with tab1:
                st.write("**Primeiras 5 linhas das features:**")
                st.dataframe(X.head(), use_container_width=True)
                
                st.write("**Primeiras 5 valores do target:**")
                st.dataframe(y.head().to_frame(), use_container_width=True)
            
            with tab2:
                st.write("**Estat√≠sticas das features:**")
                st.dataframe(X.describe(), use_container_width=True)
        
        # Bot√µes de navega√ß√£o
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            if st.button("‚¨ÖÔ∏è Voltar", use_container_width=True):
                st.session_state.step = 1
                st.rerun()
        
        with col3:
            if st.button("ü§ñ Iniciar Treinamento", type="primary", use_container_width=True):
                st.session_state.step = 3
                st.rerun()
    
    def step_train(self):
        """Passo 3: Treinamento dos modelos"""
        st.markdown("## ü§ñ Treinamento de Modelos")
        
        if not st.session_state.processed:
            st.warning("‚ö†Ô∏è Dados n√£o processados.")
            st.session_state.step = 2
            st.rerun()
            return
        
        X = st.session_state.X
        y = st.session_state.y
        problem_type = st.session_state.problem_type
        
        # Informa√ß√µes sobre o treinamento
        st.info(f"""
        **Configura√ß√£o do Treinamento:**
        - Tipo: {problem_type.upper()}
        - Features: {X.shape[1]}
        - Amostras: {X.shape[0]}
        - Modelos: 7 algoritmos diferentes
        - Valida√ß√£o: 3-fold cross-validation
        """)
        
        # Iniciar treinamento
        if st.button("üöÄ Iniciar Treinamento Completo", type="primary", use_container_width=True):
            with st.spinner("Treinando modelos... Isso pode levar alguns minutos"):
                # Criar e treinar modelos
                trainer = SimpleModelTrainer(problem_type)
                results, best_model = trainer.train_models(X, y)
                
                # Salvar resultados
                st.session_state.results = results
                st.session_state.trainer = trainer
                st.session_state.best_model = best_model
                
                # Ir para resultados
                st.session_state.step = 4
                st.rerun()
        
        # Bot√£o para voltar
        if st.button("‚¨ÖÔ∏è Voltar", use_container_width=True):
            st.session_state.step = 2
            st.rerun()
    
    def step_results(self):
        """Passo 4: Resultados"""
        st.markdown("## üìä Resultados do Treinamento")
        
        if st.session_state.results is None:
            st.warning("‚ö†Ô∏è Nenhum resultado dispon√≠vel.")
            if st.button("‚¨ÖÔ∏è Voltar para Treinamento"):
                st.session_state.step = 3
                st.rerun()
            return
        
        results = st.session_state.results
        trainer = st.session_state.trainer
        problem_type = st.session_state.problem_type
        
        # M√©tricas do melhor modelo
        best_model_name = trainer.best_model_name
        best_metrics = results[best_model_name]
        
        # Cart√µes de m√©tricas
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("üèÜ Melhor Modelo", best_model_name)
        
        with col2:
            if problem_type == 'classification':
                st.metric("üéØ Acur√°cia", f"{best_metrics['accuracy']:.3f}")
            else:
                st.metric("üéØ R¬≤ Score", f"{best_metrics['r2']:.3f}")
        
        with col3:
            if problem_type == 'classification':
                st.metric("üìà F1-Score", f"{best_metrics['f1_score']:.3f}")
            else:
                st.metric("üìà RMSE", f"{best_metrics['rmse']:.3f}")
        
        with col4:
            st.metric("ü§ñ Modelos Treinados", len(results))
        
        # Ranking dos modelos
        st.markdown("### üèÜ Ranking dos Modelos")
        
        ranking_df = trainer.get_ranking()
        st.dataframe(ranking_df, use_container_width=True)
        
        # Gr√°fico do ranking
        st.markdown("### üìà Visualiza√ß√£o do Ranking")
        
        if problem_type == 'classification':
            fig = px.bar(
                ranking_df,
                x='Modelo',
                y='Acur√°cia',
                title='Acur√°cia por Modelo',
                color='Acur√°cia',
                color_continuous_scale='Viridis',
                text='Acur√°cia'
            )
        else:
            fig = px.bar(
                ranking_df,
                x='Modelo',
                y='R¬≤',
                title='R¬≤ Score por Modelo',
                color='R¬≤',
                color_continuous_scale='Viridis',
                text='R¬≤'
            )
        
        fig.update_traces(texttemplate='%{text:.3f}', textposition='outside')
        fig.update_layout(xaxis_tickangle=-45, height=500)
        st.plotly_chart(fig, use_container_width=True)
        
        # Abas de detalhes
        tab1, tab2, tab3 = st.tabs(["üìã Detalhes", "üíæ Exportar", "üîÑ Novo"])
        
        with tab1:
            st.markdown("#### üìä M√©tricas Detalhadas")
            
            # Tabela completa de m√©tricas
            metrics_df = pd.DataFrame(results).T
            st.dataframe(metrics_df, use_container_width=True)
            
            # Compara√ß√£o visual
            st.markdown("#### üìà Compara√ß√£o entre Modelos")
            
            models = list(results.keys())
            
            if problem_type == 'classification':
                scores = [results[m]['accuracy'] for m in models]
                metric_name = 'Acur√°cia'
            else:
                scores = [results[m]['r2'] for m in models]
                metric_name = 'R¬≤'
            
            fig2 = go.Figure(data=[
                go.Bar(
                    x=models, 
                    y=scores,
                    marker_color=['#FF6B6B' if m == best_model_name else '#4ECDC4' for m in models],
                    text=[f'{s:.3f}' for s in scores],
                    textposition='auto'
                )
            ])
            
            fig2.update_layout(
                title=f'{metric_name} - Compara√ß√£o',
                xaxis_title='Modelo',
                yaxis_title=metric_name,
                height=400
            )
            
            st.plotly_chart(fig2, use_container_width=True)
        
        with tab2:
            st.markdown("#### üíæ Exportar Resultados")
            
            col1, col2, col3 = st.columns(3)
            
            with col1:
                # Exportar ranking
                ranking_csv = ranking_df.to_csv(index=False).encode()
                st.download_button(
                    label="üìä Ranking CSV",
                    data=ranking_csv,
                    file_name="ranking_modelos.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with col2:
                # Exportar m√©tricas completas
                metrics_csv = pd.DataFrame(results).T.to_csv().encode()
                st.download_button(
                    label="üìà M√©tricas CSV",
                    data=metrics_csv,
                    file_name="metricas_completas.csv",
                    mime="text/csv",
                    use_container_width=True
                )
            
            with col3:
                # Salvar melhor modelo
                if st.button("ü§ñ Salvar Modelo", use_container_width=True):
                    model_path = "melhor_modelo.pkl"
                    joblib.dump(trainer.best_model, model_path)
                    
                    with open(model_path, "rb") as f:
                        model_bytes = f.read()
                    
                    st.download_button(
                        label="‚¨áÔ∏è Baixar .pkl",
                        data=model_bytes,
                        file_name="melhor_modelo.pkl",
                        mime="application/octet-stream",
                        use_container_width=True
                    )
            
            # Relat√≥rio de an√°lise
            st.markdown("---")
            st.markdown("#### üìÑ Relat√≥rio de An√°lise")
            
            report = f"""
            # Relat√≥rio de AutoML
            Data: {datetime.now().strftime('%d/%m/%Y %H:%M')}
            
            ## Resumo
            - Tipo de problema: {problem_type.upper()}
            - Melhor modelo: {best_model_name}
            - Total de modelos treinados: {len(results)}
            
            ## M√©tricas do Melhor Modelo
            """
            
            if problem_type == 'classification':
                report += f"""
                - Acur√°cia: {best_metrics['accuracy']:.4f}
                - F1-Score: {best_metrics['f1_score']:.4f}
                - CV Score: {best_metrics['cv_mean']:.4f} ¬± {best_metrics['cv_std']:.4f}
                """
            else:
                report += f"""
                - R¬≤ Score: {best_metrics['r2']:.4f}
                - RMSE: {best_metrics['rmse']:.4f}
                - CV Score: {best_metrics['cv_mean']:.4f} ¬± {best_metrics['cv_std']:.4f}
                """
            
            report += "\n\n## Ranking Completo\n" + ranking_df.to_markdown()
            
            st.download_button(
                label="üìÑ Baixar Relat√≥rio",
                data=report.encode(),
                file_name="relatorio_automl.md",
                mime="text/markdown",
                use_container_width=True
            )
        
        with tab3:
            st.markdown("#### üîÑ Novo Treinamento")
            
            st.info("""
            Clique no bot√£o abaixo para:
            1. Limpar todos os resultados atuais
            2. Voltar √† tela inicial
            3. Come√ßar um novo treinamento
            """)
            
            if st.button("üîÑ Iniciar Novo Projeto", type="primary", use_container_width=True):
                # Limpar estado da sess√£o
                keys_to_keep = ['scale_features']
                keys_to_delete = [k for k in st.session_state.keys() if k not in keys_to_keep]
                
                for key in keys_to_delete:
                    del st.session_state[key]
                
                st.session_state.step = 1
                st.rerun()
        
        # Bot√£o para voltar
        if st.button("‚¨ÖÔ∏è Voltar para Treinamento", use_container_width=True):
            st.session_state.step = 3
            st.rerun()

# ========== IMPORTS ADICIONAIS ==========
import io

# ========== EXECU√á√ÉO ==========
if __name__ == "__main__":
    app = AutoMLApp()
    app.run()